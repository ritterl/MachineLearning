{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM31zU3QVyYFcMX3jb7BGiF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritterl/MachineLearning/blob/master/Chapter10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taYEBN2b6j-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext rpy2.ipython"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pstxqq-xHwr6",
        "colab_type": "text"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WCzthDOqLQz",
        "colab_type": "text"
      },
      "source": [
        "In this notebook, chapter 10 of [Machine Learning](https://www.amazon.de/Machine-Learning-techniques-predictive-modeling-ebook/dp/B07PYXX3H5) with R is summarized and the code samples are described. This section of the book serves to show how machine learning algorithms can be evaluated. More precisely, it gives reasons why also other measures than predictive accuracy are needed to assess performance. Further, approaches to ensure that the performance measures reasonably reflect a model's ability to predict or forecast unseen cases are provided. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QsUZ7XTyJp0",
        "colab_type": "text"
      },
      "source": [
        "By simply dividing the number of correct predictions by the total number of predictions, a wrong picture about the performance of the classifier may occur. This especially arises in datasets with a large class imbalance and is also referred to as **class imbalance problem**. For instance, a positive event occurs very often (in say 99% of the cases), a model which predicts always a positive case has an accuracy of 99%. However, it is not useful for predicting the negative cases. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oVcK8pQMxpJ",
        "colab_type": "text"
      },
      "source": [
        "Besides the two important data types: **actual class values** and **predicted class values** which are obvious, however, the majority of models can deliver another important type of information: the **estimated probability of the prediction** or in other words the confidence of the model about a particular decision. So, when comparing two models with the same number of mistakes, it is possible to say that the one which makes better assessments regarding its uncertainty is smarter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkLp-x-fjC42",
        "colab_type": "text"
      },
      "source": [
        "First of all, the predicted probabilities from the SMS model developed in chapter 4 of the book are drawn. Therefore, it is important to note that the code of chapter 4 needs to be executed prior to this section. In this example, the predict () function gives the probability for each possible outcome. Each line of the following output sums up to 1 due to the fact that these are mutually exclusive and exhaustive events. In other words: An SMS can only either be \"ham\" or \"spam\", but not both at the same time and it cannot be something else or something in between. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge6rq4Jvn6SS",
        "colab_type": "text"
      },
      "source": [
        "In a next step, the results are combined into a data frame. (Do I even need line 10 - 19 if I have the csv-file sms_results already? --> no!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsiYmbmr19ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%R\n",
        "sms_classifier <- load(\"sms_classifier.RData\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79dLLy_C1zcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%R\n",
        "# obtain the predicted probabilities\n",
        "sms_test_prob <- predict(sms_classifier, sms_test, type = \"raw\")\n",
        "head(sms_test_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyDcxbFy5_r3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%R\n",
        "## Confusion matrixes in R ----\n",
        "sms_results <- read.csv(\"sms_results.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMLR4-B-6Z8A",
        "colab_type": "text"
      },
      "source": [
        "In this step a first glimpse into the sms_results is made. It shows the actual type as well as the predicted type on the LHS and on the RHS the probability (estimated by the model) of the object being either spam or ham. As it can be observed, the model was extremely certain about its decisions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of_z3MFw1h4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8053ecc1-b600-4410-8567-89c8cfdc2d5a"
      },
      "source": [
        "%%R\n",
        "# the first several test cases\n",
        "head(sms_results)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  actual_type predict_type prob_spam prob_ham\n",
            "1         ham          ham   0.00000  1.00000\n",
            "2         ham          ham   0.00000  1.00000\n",
            "3         ham          ham   0.00016  0.99984\n",
            "4         ham          ham   0.00004  0.99996\n",
            "5        spam         spam   1.00000  0.00000\n",
            "6         ham          ham   0.00020  0.99980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS4f7LPw7D-d",
        "colab_type": "text"
      },
      "source": [
        "In the previous cases, the model was very confident, but of course, there are also other cases in which the model was unconfident about its decision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi3RI3Er8BSn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3ba266b8-0ef4-4843-f0a3-eaacf14f8277"
      },
      "source": [
        "%%R\n",
        "head(subset(sms_results, prob_spam > 0.40 & prob_spam < 0.60))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     actual_type predict_type prob_spam prob_ham\n",
            "377         spam          ham   0.47536  0.52464\n",
            "717          ham         spam   0.56188  0.43812\n",
            "1311         ham         spam   0.57917  0.42083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNTw5YZH8WFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1a145a14-863f-4555-9689-98047868c1b8"
      },
      "source": [
        "%%R\n",
        "head(subset(sms_results, actual_type != predict_type))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    actual_type predict_type prob_spam prob_ham\n",
            "53         spam          ham   0.00071  0.99929\n",
            "59         spam          ham   0.00156  0.99844\n",
            "73         spam          ham   0.01708  0.98292\n",
            "76         spam          ham   0.00851  0.99149\n",
            "184        spam          ham   0.01243  0.98757\n",
            "332        spam          ham   0.00003  0.99997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqwfFpvv8hor",
        "colab_type": "text"
      },
      "source": [
        "Especially in this cases the question can be posed, whether the model is useful or not. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD6Dz6QhUp73",
        "colab_type": "text"
      },
      "source": [
        "In the next passage **confusion matrices** will be introduced. A confusion matrix has two dimensions. One dimension displays the actual values (rows) and the other dimension displays the predicted values (columns). In the diagonal cells the model predicted the actual value correct and in the off-diagonal cells the predictions were incorrect. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPBevmrmUqMk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7b578e4d-50ee-4d11-8d37-64060243c747"
      },
      "source": [
        "%%R\n",
        "table(sms_results$actual_type, sms_results$predict_type)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      \n",
            "        ham spam\n",
            "  ham  1203    4\n",
            "  spam   31  152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms1X6hsAX6II",
        "colab_type": "text"
      },
      "source": [
        "With the introduction of confusion matrices, also a new terminology needs to be implemented, whereas first of all the class of interest needs to be defined. In the ham/spam example, \"spam\" is referred to as the **positive class**, since the spam-filter is interested in finding spam messages. Consequently, the **negative class** are the ham messages. It should be obvious that positive and negative are not related with \"good and bad\", but solely needed to distinguish between the different classes. \n",
        "However, now it is possible to implement this terminology in the confusion matrix. \n",
        "- predicted spam / actual spam = True positive (TP -> 152)\n",
        "- predicted ham / acutal ham = True negative (TN -> 1203)\n",
        "- predicted spam / actual ham = False positive (FP -> 4)\n",
        "- predicted ham / actual spam = False negative (FN -> 31)\n",
        "\n",
        "\n"
      ]
    }
  ]
}